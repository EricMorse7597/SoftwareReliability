\section{Findings}
\label{Findings}

Replace all this with the findings (analysis and results) from your research project.  The Findings section presents the results of the research without interpretation or analysis. It includes the key data or outcomes derived from the methods used, such as statistical results, experimental observations, or case study outcomes. The findings are often displayed through tables, graphs, or charts to clearly communicate the results. The goal is to objectively present the evidence generated by the research, allowing the reader to see what was discovered before the interpretation is provided in the discussion section. 

This section presents the qualitative and quantitative findings from this study.

\subsection{Quantitative Findings}
The following section provides an overview of the key findings from using ChatGPT to support co-authoring of academic critiques based on the readability scores for `student authored' vs. `student and ChatGPT co-authored.'  Table~\ref{tab:student_authored_readability_results} presents a comprehensive report of the readability analysis including standard descriptive statistics for `student authored' critiques for the entire term (i.e., weeks 1-8). Each entry represents the group mean for that specific week for the respective readability metric.

% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
% \usepackage[table,xcdraw]{xcolor}
% Beamer presentation requires \usepackage{colortbl} instead of \usepackage[table,xcdraw]{xcolor}
\begin{table*}[h!]
	\centering
	\caption{Comprehensive Readability Metrics with Standard Descriptive Statistics for Student Authored Critiques (weeks 1-8)}
	\label{tab:student_authored_readability_results}
	\resizebox{\textwidth}{!}{%
		\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
			\hline
			\rowcolor[HTML]{DAE8FC} 
			\textbf{Week} &
			\textbf{\begin{tabular}[c]{@{}c@{}}Flesch-Kincaid \\ Score\end{tabular}} &
			\textbf{\begin{tabular}[c]{@{}c@{}}Flesch Reading \\ Ease\end{tabular}} &
			\textbf{\begin{tabular}[c]{@{}c@{}}Dale Chall \\ Readability Score\end{tabular}} &
			\textbf{\begin{tabular}[c]{@{}c@{}}ARI \\ Score\end{tabular}} &
			\textbf{\begin{tabular}[c]{@{}c@{}}Coleman Liau \\ Index Score\end{tabular}} &
			\textbf{\begin{tabular}[c]{@{}c@{}}Gunning \\ Fog Score\end{tabular}} &
			\textbf{\begin{tabular}[c]{@{}c@{}}Linsear \\ Write Score\end{tabular}} &
			\textbf{\begin{tabular}[c]{@{}c@{}}SMOG \\ Score\end{tabular}} \\ \hline
			1                & 13.54 & 34.74 & 11.00 & 13.98 & 13.57 & 16.37 & 15.63 & 15.04 \\ \hline
			2                & 14.02 & 29.87 & 11.53 & 14.89 & 15.14 & 16.52 & 15.49 & 15.41 \\ \hline
			3                & 14.06 & 30.52 & 11.25 & 14.76 & 14.70 & 16.23 & 15.80 & 15.71 \\ \hline
			4                & 13.97 & 31.38 & 11.51 & 14.62 & 14.45 & 15.77 & 15.63 & 15.61 \\ \hline
			5                & 13.52 & 32.65 & 11.28 & 14.14 & 14.47 & 15.63 & 14.63 & 15.26 \\ \hline
			6                & 13.97 & 28.79 & 11.70 & 14.75 & 15.47 & 16.24 & 14.85 & 15.24 \\ \hline
			7                & 14.15 & 29.69 & 11.40 & 15.03 & 15.09 & 16.44 & 15.72 & 15.53 \\ \hline
			8                & 14.83 & 24.32 & 11.39 & 15.59 & 15.99 & 16.51 & 15.73 & 15.34 \\ \hline
			\rowcolor[HTML]{EFEFEF} 
			\textbf{Min}     & 13.52 & 24.32 & 11.00 & 13.98 & 13.57 & 15.63 & 14.63 & 15.04 \\ \hline
			\rowcolor[HTML]{EFEFEF} 
			\textbf{Max}     & 14.83 & 34.74 & 11.70 & 15.59 & 15.99 & 16.52 & 15.80 & 15.71 \\ \hline
			\rowcolor[HTML]{EFEFEF} 
			\textbf{Mean}    & 14.01 & 30.24 & 11.38 & 14.72 & 14.86 & 16.21 & 15.44 & 15.39 \\ \hline
			\rowcolor[HTML]{EFEFEF} 
			\textbf{Std Dev} & 0.41  & 3.05  & 0.21  & 0.50  & 0.74  & 0.34  & 0.44  & 0.22  \\ \hline
		\end{tabular}%
	}
\end{table*}

It can be seen that the readability generally decreased as the term went on.  This was particularly evident for the Flesch Reading Ease which started at 34.74 and declined to 24.32 at the end of the term (week 8).  When referencing the mean, the readability levels across the entire group and the term, were: Flesch-Kincaid Score: 14.01 (college/university level), Flesch Reading Score: 30.24 (college/college graduate), Dale Chall: 11.38 (graduate level), ARI: 14.72 (college level), Coleman-Liau: 14.86 (graduate level), Gunning Fog: 16.21 (college senior), Linsear: 15.44 (college senior), and SMOG: 15.39 (undergraduate).

Table~\ref{tab:student_authored_and_ChatGPT_readability_results} presents the readability analysis including standard descriptive statistics for `student and ChatGPT co-authored' critiques for the term. 

% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
% \usepackage[table,xcdraw]{xcolor}
% Beamer presentation requires \usepackage{colortbl} instead of \usepackage[table,xcdraw]{xcolor}
\begin{table*}[h!]
	\centering
	\caption{Comprehensive Readability Metrics with Standard Descriptive Statistics for Student and ChatGPT co-Authored Critiques (weeks 1-8)}
	\label{tab:student_authored_and_ChatGPT_readability_results}
	\resizebox{\textwidth}{!}{%
		\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
			\hline
			\rowcolor[HTML]{DAE8FC} 
			\textbf{Week} &
			\textbf{\begin{tabular}[c]{@{}c@{}}Flesch-Kincaid \\ Score\end{tabular}} &
			\textbf{\begin{tabular}[c]{@{}c@{}}Flesch Reading \\ Ease\end{tabular}} &
			\textbf{\begin{tabular}[c]{@{}c@{}}Dale Chall \\ Readability Score\end{tabular}} &
			\textbf{\begin{tabular}[c]{@{}c@{}}ARI \\ Score\end{tabular}} &
			\textbf{\begin{tabular}[c]{@{}c@{}}Coleman Liau \\ Index Score\end{tabular}} &
			\textbf{\begin{tabular}[c]{@{}c@{}}Gunning \\ Fog Score\end{tabular}} &
			\textbf{\begin{tabular}[c]{@{}c@{}}Linsear \\ Write Score\end{tabular}} &
			\textbf{\begin{tabular}[c]{@{}c@{}}SMOG \\ Score\end{tabular}} \\ \hline
			1                & 14.65 & 26.88 & 11.65 & 15.26 & 15.12 & 17.44 & 16.33 & 16.40 \\ \hline
			2                & 15.02 & 22.79 & 12.06 & 15.88 & 16.38 & 17.65 & 16.18 & 16.14 \\ \hline
			3                & 15.26 & 20.96 & 12.18 & 16.07 & 16.64 & 17.48 & 16.24 & 16.59 \\ \hline
			4                & 14.90 & 24.95 & 12.00 & 15.62 & 15.62 & 16.82 & 16.29 & 16.29 \\ \hline
			5                & 14.01 & 27.51 & 11.75 & 14.75 & 15.77 & 16.06 & 14.44 & 15.39 \\ \hline
			6                & 14.52 & 24.61 & 12.09 & 15.23 & 16.12 & 16.96 & 15.16 & 15.59 \\ \hline
			7                & 14.71 & 24.49 & 11.93 & 15.54 & 16.11 & 16.91 & 15.73 & 15.96 \\ \hline
			8                & 16.06 & 15.50 & 12.09 & 16.85 & 17.56 & 18.00 & 16.55 & 15.65 \\ \hline
			\rowcolor[HTML]{EFEFEF} 
			\textbf{Min}     & 14.01 & 15.50 & 11.65 & 14.75 & 15.12 & 16.06 & 14.44 & 15.39 \\ \hline
			\rowcolor[HTML]{EFEFEF} 
			\textbf{Max}     & 16.06 & 27.51 & 12.18 & 16.85 & 17.56 & 18.00 & 16.55 & 16.59 \\ \hline
			\rowcolor[HTML]{EFEFEF} 
			\textbf{Mean}    & 14.89 & 23.46 & 11.97 & 15.65 & 16.17 & 17.16 & 15.87 & 16.00 \\ \hline
			\rowcolor[HTML]{EFEFEF} 
			\textbf{Std Dev} & 0.60  & 3.83  & 0.18  & 0.63  & 0.73  & 0.60  & 0.72  & 0.43  \\ \hline
		\end{tabular}%
	}
\end{table*}

A similar pattern emerged as in Table~\ref{tab:student_authored_readability_results}.  The  Flesch Reading Ease started at 26.88 and declined to 15.50 by week 8.  Using the mean of the readability scores across the group yielded the following results: Flesch-Kincaid Score: 14.89 (college/university level), Flesch Reading Score: 23.46 (college graduate), Dale Chall: 11.97 (graduate level), ARI: 15.65 (college level), Coleman-Liau: 16.17 (graduate level), Gunning Fog: 17.16 (college senior), Linsear: 15.87 (college senior), and SMOG: 16.00 (undergraduate).

Figure~\ref{fig:student-authored-critique-readability-scores} presents the weekly `student authored' readability score analysis over the term.  The most obvious pattern is the Flesch Reading score which shows a general decreasing trend throughout the term.  The other readability scores were relatively consistent throughout the term. 

\begin{figure}[h!]
	\centering
	\includegraphics[width=1.0\linewidth]{"figures/Student Authored"}
	\caption[Weekly Student Authored Critique Readability Scores]{Weekly 'Student Authored' Critique Readability Score Analysis over the term}
	\label{fig:student-authored-critique-readability-scores}
\end{figure}


%Figure~\ref{fig:student-and-chatgpt-co-authored-readability-scores} presents the weekly `student authored anc ChatGPT co-authored' readability score analysis over the term.  As in Figure~\ref{fig:student-authored-critique-readability-scores}, the most evident pattern is the Flesch Reading score which shows a general decreasing trend throughout the term.  The other readability scores were relatively consistent throughout the term. 

Figure~\ref{fig:student-and-chatgpt-co-authored-readability-scores} displays the weekly readability score analysis for critiques co-authored by students and ChatGPT over the term. Similar to the trends observed in Figure~\ref{fig:student-authored-critique-readability-scores}, the most notable pattern is the general decline in the Flesch Reading Ease score throughout the term. Other readability metrics remained relatively stable over the period.

\begin{figure}[h!]
	\centering
	\includegraphics[width=1.0\linewidth]{"figures/Student and ChatGPT Co-Authored"}
	\caption[`Student and ChatGPT Co-Authored' Critique Readabilty Scores]{Weekly `Student and ChatGPT Co-Authored' Critique Readabilty Score Analysis over the term}
	\label{fig:student-and-chatgpt-co-authored-readability-scores}
\end{figure}

\textbf{Statistical Analysis and ANOVA Results}
Prior to performing the ANOVAs, we verified the necessary assumptions to ensure the appropriateness of the statistical models. These assumptions included the independence of observations, normality of the data distributions, and homogeneity of variances. The Shapiro-Wilk test was used to confirm normality \cite{ShapiroWilk_1965}, and Levene's test was applied to assess the homogeneity of variances \cite{Levene_1960}.

After confirming these assumptions, ANOVAs were conducted for each readability metric to determine if there were statistically significant differences between critiques authored solely by students and those co-authored with ChatGPT. The results are as follows:

\begin{itemize}
	\item \textit{Flesch-Kincaid Score}: Significant difference; \(F(1, 14) = 11.974\), \(p = 0.003\).
	\item \textit{Flesch Reading Ease}: Significant difference; \(F(1, 14) = 15.356\), \(p = 0.0015\).
	\item \textit{Dale Chall Score}: Significant difference; \(F(1, 14) = 34.994\), \(p < 0.0001\).
	\item \textit{ARI Score}: Significant difference; \(F(1, 14) = 10.558\), \(p = 0.005\).
	\item \textit{Coleman Liau Index}: Significant difference; \(F(1, 14) = 12.609\), \(p = 0.003\).
	\item \textit{Gunning Fog Score}: Significant difference; \(F(1, 14) = 15.076\), \(p = 0.001\).
	\item \textit{Linsear Write Score}: No significant difference; \(F(1, 14) = 2.050\), \(p = 0.174\).
	\item \textit{SMOG Score}: Significant difference; \(F(1, 14) = 12.707\), \(p = 0.003\).
\end{itemize}

The results indicate that for all metrics except the Linsear Write Score, there were statistically significant differences between the student-authored and ChatGPT co-authored critiques over the eight weeks. These findings suggest that the integration of AI like ChatGPT in the writing process significantly influences the readability and possibly the quality of student critiques.

Interestingly, the decrease in readability scores over time, especially in measures like the Flesch Reading Ease, might reflect a transition towards more complex academic language. This trend could be attributed to the students' exposure to high-quality academic literature and their advancement in understanding and synthesizing complex concepts. It appears that as students engaged with seminal works and sophisticated material, their ability to emulate academic rigour in their own writing improved, leading to the production of text that, while potentially more challenging for lay readers, aligns more closely with fourth-year undergraduate and graduate-level standards. This evolution in writing style underscores the effectiveness of AI tools in fostering higher-order cognitive skills, including critical analysis and academic writing prowess.


\subsubsection{Individual student performance observations}
\hfill \break
Deeper investigations on specific participants yielded some interesting results.  The following examples illustrate these findings.
\hfill \break
\hfill \break
\textbf{Participant \#23:}
\textit{Flesch Reading Ease:} In one critique, the score improved from a very low 4.728 to a higher 10.666. This is a significant improvement in readability, suggesting that the co-authoring process made the document more readable.
\textit{Gunning Fog Score:} In the same document, the score changed from 19.783 to 18.669 with the assistance from ChatGPT. This indicates a reduction in sentence complexity, contributing to better readability.

\hfill \break
\textbf{Participant \#22:}
\textit{Flesch Reading Ease:} For one critique, the score dropped slightly from 36.667 to 32.726. While this is a decrease, it's still within a range that suggests good readability, possibly indicating a more balanced approach to complexity and readability in the co-authored version.

\hfill \break
\textbf{Participant \#3:}
\textit{Flesch Reading Ease:} Improved from 23.316 to 27.886 in one document, indicating an increase in readability.
\textit{Linsear Write Score:} Decreased from 13.115 to 12.538, which points towards simpler sentence structure.
\hfill \break


\subsection{Qualitative Observations}
In several cases, the co-authored documents show an improvement in readability scores, suggesting that ChatGPT can help in making complex academic content more accessible.

Conversely, there are instances where the complexity of the documents increased, possibly reflecting a deeper level of analysis or more advanced vocabulary and sentence structures due to the academic nature of the critiques. Some documents show a balance between maintaining academic rigour and ensuring readability, which is crucial in educational settings.

