\section{Methodology}
\label{Methodology}

Replace all this with your specific methodology that you used in your Software Testing research project.  The Methodology section explains how the research was conducted in detail. It provides a clear and precise description of the study design, data collection methods, tools or instruments used, and the procedures followed. This section also outlines the sampling techniques, participants or data sources, and any statistical or analytical methods applied. The goal of the methodology is to allow other researchers to replicate the study or understand how the results were derived. It should be detailed enough to ensure transparency and reproducibility while justifying why certain methods were chosen. 

This comprehensive study was implemented during the Fall 2023 semester with fourth-year undergraduate students enrolled in the Ubiquitous Computing (UbiCom) course in the Computer Science department\footnote{This research was approved by Sheridan's Research Ethics Board No. 2023-10-001-022.}. The methodology included multiple components designed to rigorously evaluate the effectiveness of AI-assisted academic critiques.

\subsection{Participants}
Participants were recruited through convenience sampling through advertisements throughout the Computer Science Club, course postings, and other mediums available at the education institution.  There were a total of  22 participants involved in this study all in their final year of study in their Honours Bachelor of Computer Science baccalaureate degree.  There were 5 females and 17 males; the minimum age was 21, the mean was 25, and the maximum age was 31.

\subsection{Detailed Process of Critique Assignment}
Each week, students were assigned two academic papers centred around pivotal UbiCom topics such as Smart Homes, Smart Cities, IoT, and Wearable Technology. These topics were chosen to ensure that students were exposed to diverse applications and theoretical advancements within the field of Ubiquitous Computing. The selection process involved curating papers that varied in complexity and scope, providing a robust testbed for critique development.  Seminal papers were selected, such as, Mark Weiser's `The computer for the 21st century' in 1999~\cite{Weiser_1999}. Mark Weiser is often referred to as the father of ubiquitous computing~\cite{brown2020_language}.

\begin{quotation}
\textit{... Now we are in the personal computing era, person and machine staring uneasily at each other across the desktop. Next comes ubiquitous computing, or the age of calm technology, when technology recedes into the background of our lives.}
\textemdash Mark Weiser
\end{quotation}

Other papers provided a survey of the state-of-the-art in a specific area (e.g., Smart Cities).  For example, `Systematic literature review of context-awareness applications supported by smart cities’ infrastructures'~\cite{Rocha_2022_SmartCities}.

\subsection{Baseline and AI-Assisted Critique Process}
Initially, critiques were written individually, and independently, without the assistance of any Generative AI assistance (e.g., ChatGPT, Bing, etc.) to establish a baseline for each student's analytical and writing abilities. Students were then asked to write critiques with the assistance of ChatGPT, following a structured well-defined methodology.  Students were also given a 1-hour training session on effective prompt engineering and how to objectively assess ChatGPT's responses. This session aimed to empower students with the skills needed to elicit detailed and specific feedback from ChatGPT, enhancing their ability to refine their arguments and writing clarity. 

\subsection{Continuous Feedback and Iteration}
A critical component of the methodology was the continuous feedback mechanism. After each AI-assisted critique, students received personalized feedback from both the course instructor and the AI, highlighting areas of improvement and success. This feedback loop was essential for guiding students' development over the semester and for refining the use of AI in the critique process.  The students were asked to elicit feedback from ChatGPT at most 3 times.  Please see the Appendix for the full details of the assignment.

\subsection{Comprehensive Evaluation Metrics}
The assignments were evaluated using a combination of quantitative and qualitative metrics, as described below.

\subsubsection{Quantitative Metrics} 
The core metrics were the readability tests. A suite of these tests were applied to each critique, providing a multifaceted view of how readability evolved with AI integration. This included advanced readability formulas that assessed not only text difficulty but also engagement and grade-appropriateness of the content.

Additional metrics collected and analyzed included the critiques' length, structure, and complexity changes from baseline to AI-assisted versions.  The specific readability metrics computed were: \textit{Flesch-Kincaid Score}, \textit{Flesch Reading Ease}, \textit{Dale Chall Readability Score}, \textit{ARI Score}, \textit{Coleman Liau Index Score}, \textit{Gunning Fog Score}, \textit{Linsear Write Score}, and \textit{SMOG Score}.

\textbf{Statistical Analysis}
Statistical analyses were performed on the readability data collected. Standard descriptive statistics were computed. Furthermore, we aimed to determine if there were any statistical differences over time in the readability scores, both between and within the groups: `student-authored only' and `student-and-ChatGPT-co-authored' critiques. These comparisons were made by examining the weekly critiques for most of the term. Due to the non-parametric nature of the data, one-way repeated measures ANOVAs using the Friedman test were computed.

\subsubsection{Qualitative Metrics}
Evaluations were further deepened by analyzing the critiques for argumentative depth, logical coherence, and the use of evidence, which were scored using a rubric developed specifically for this course.

\textit{Educational Outcomes Monitoring:}
Beyond the critique process, the study monitored broader educational outcomes, such as student engagement, perceived ease of completing assignments, and overall satisfaction with the learning process. Surveys and interviews were conducted at the beginning, middle, and end of the semester to capture students’ attitudes towards the use of AI in their learning process.

\textit{Ethical Considerations and Bias Monitoring:}
Given the use of AI in educational settings, the study also addressed ethical considerations, particularly concerning the dependence on technology and the potential for AI to introduce biases into the students' work. Measures were put in place to monitor and mitigate any adverse effects, ensuring that the AI's integration was both responsible and beneficial.